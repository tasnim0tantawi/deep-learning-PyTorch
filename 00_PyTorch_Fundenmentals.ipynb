{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFIDXd6k7reP9e7qYyVwBl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tasnim0tantawi/deep-learning-PyTorch/blob/main/00_PyTorch_Fundenmentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvQYqAg4z_V1",
        "outputId": "7e1d9c3c-2033-4f20-e3d4-84004af69b3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Tensors"
      ],
      "metadata": {
        "id": "AVBwjI5Q1HhJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Types of Tensors: \n",
        "\n",
        "1.   Scalar\n",
        "2.   Vector\n",
        "3.   Matrix\n",
        "4.   Tensor\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lUegDKE10-Bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalar = torch.tensor(7) \n",
        "scalar.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVMzzhPI0796",
        "outputId": "2f5c303e-7cdf-4ebf-9ce8-3184b99ce3ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scalar.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oBlXbMX3ZbO",
        "outputId": "e83a227f-8404-4115-e17a-3c5bbd7dbbcc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector = torch.tensor([7, 7])\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu_pEsmI2f1H",
        "outputId": "e88fd4e3-fb46-4958-8c8d-efd137e90540"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ndim --> Number of dimenstions. Scalar has 0 dimensions. Vector has 1. Matrix has 2. We can think of dimensions as the []. \n",
        "The number of attributes, features or input variables of a dataset is referred to as its dimensionality. "
      ],
      "metadata": {
        "id": "s8o6fDUA3mCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K44aRYcl2oCZ",
        "outputId": "dd707b39-324c-43bb-d438-b98ca8e4d18b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIvibuPQ4_Xi",
        "outputId": "0ef9397e-8a9d-48cf-8ec1-8cd26a4ccfdb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX = torch.tensor([[7, 9], \n",
        "                      [8, 76],\n",
        "                      [12, 8]]\n",
        "                      )\n",
        "MATRIX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMCDj6Op5MA0",
        "outputId": "fef16818-4061-4ff5-9cae-a7aac5f99b5f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7,  9],\n",
              "        [ 8, 76],\n",
              "        [12,  8]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9yjEPBa5W1c",
        "outputId": "c62780af-c959-455f-eedc-b8afd643284a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48P7W0FB5jnJ",
        "outputId": "25026f0e-be16-4499-f1e8-60440b1b2028"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR = torch.tensor(\n",
        "    [[[2, 8, 9],\n",
        "      [5, 9, 0],\n",
        "      [5, 9, 77]\n",
        "      ]]\n",
        ")\n",
        "TENSOR\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me42lCiu5n02",
        "outputId": "8ece118a-c744-4624-99ba-416755a65ea5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 2,  8,  9],\n",
              "         [ 5,  9,  0],\n",
              "         [ 5,  9, 77]]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GErbD-S36YOV",
        "outputId": "eab47395-144f-4fd3-eda2-91160f16ebc2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNeR0sq46pZz",
        "outputId": "61ad863c-815f-4332-c92e-b9bac354d63f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UVkTXduJ6s5o"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Tensors \n",
        "We've established tensors represent some form of data.\n",
        "\n",
        "And machine learning models such as neural networks manipulate and seek patterns within tensors.\n",
        "\n",
        "But when building machine learning models with PyTorch, it's rare you'll create tenors by hand (like what we've being doing).\n",
        "\n",
        "Instead, a machine learning model often starts out with large random tensors of numbers and adjusts these random numbers as it works through data to better represent it.\n",
        "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers...`"
      ],
      "metadata": {
        "id": "36XO5_Hl--ND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor of size (3, 4)\n",
        "random_tensor = torch.rand(size=(3, 4))\n",
        "random_tensor, random_tensor.dtype\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FWHpdZo_JVz",
        "outputId": "61b8d514-3a11-4120-aa78-ab21a43d42c3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.9258, 0.2797, 0.5745, 0.1870],\n",
              "         [0.1931, 0.4586, 0.8498, 0.6143],\n",
              "         [0.7958, 0.1663, 0.2071, 0.4395]]), torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating random tensors for image representation:  [224, 224, 3] ([height, width, color_channels])."
      ],
      "metadata": {
        "id": "HiNE8K7xgvJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor of size (224, 224, 3)\n",
        "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJbFiOpsgTvH",
        "outputId": "f52e0f5c-87b4-4f5c-a65c-aa040e490295"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zeros and Ones Tensors"
      ],
      "metadata": {
        "id": "1Gl85OGBimGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zeros = torch.zeros(3, 4)\n",
        "zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgDSlkf9i0bM",
        "outputId": "71b2df99-0376-4033-9622-978a704ad132"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones = torch.ones(4, 5)\n",
        "ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCllYMzTjAsj",
        "outputId": "9fd51792-bff0-4a73-e564-8f35b7513c63"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones.dtype\n",
        "# The default data type is float32 in PyTorch. It can be changed. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qe64GbnwjWLV",
        "outputId": "40ec1e38-e46d-4026-b014-fe25ee6866f9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a range and tensors like"
      ],
      "metadata": {
        "id": "oCo9qbaRikEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(1, 11) # creating a range from 1 to 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGHBxfpuj8z3",
        "outputId": "d4fae25e-cda0-4cb2-d5ea-b143099c9440"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(start=0, end=11, step=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxB_ftfSkKmV",
        "outputId": "037d94cb-6dfd-4e4a-dfb3-8c310133a700"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  2,  4,  6,  8, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensors like\n",
        "ten_zeroes = torch.zeros_like(input= torch.arange(start=0, end=11, step=1))\n",
        "ten_zeroes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkYQWUM0kbv2",
        "outputId": "c0bf9acb-78d6-432f-f3b2-389d24a2b3e7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor datatypes\n",
        "There are many different tensor datatypes available in PyTorch.\n",
        "\n",
        "Some are specific for CPU and some are better for GPU.\n",
        "\n",
        "Getting to know which is which can take some time.\n",
        "\n",
        "Generally if you see torch.cuda anywhere, the tensor is being used for GPU (since Nvidia GPUs use a computing toolkit called CUDA).\n",
        "\n",
        "The most common type (and generally the default) is torch.float32 or torch.float.\n",
        "\n",
        "This is referred to as \"32-bit floating point\".\n",
        "\n",
        "But there's also 16-bit floating point (torch.float16 or torch.half) and 64-bit floating point (torch.float64 or torch.double).\n",
        "\n",
        "And to confuse things even more there's also 8-bit, 16-bit, 32-bit and 64-bit integers.\n",
        "The reason for all of these is to do with precision in computing.\n",
        "\n",
        "Precision is the amount of detail used to describe a number.\n",
        "\n",
        "The higher the precision value (8, 16, 32), the more detail and hence data used to express a number.\n",
        "\n",
        "This matters in deep learning and numerical computing because you're making so many operations, the more detail you have to calculate on, the more compute you have to use.\n",
        "\n",
        "So lower precision datatypes are generally faster to compute on but sacrifice some performance on evaluation metrics like accuracy (faster to compute but less accurate)."
      ],
      "metadata": {
        "id": "kvoKbhxOnsUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Default datatype for tensors is float32\n",
        "tensor_32 = torch.tensor([3.0, 6.0, 9.0],\n",
        "                        dtype=None, # defaults to None, which is torch.float32, can be changed\n",
        "                        device=None, # defaults to None, which uses the CPU, we can change it to use a GPU.\n",
        "                        requires_grad=False) # if True, operations perfromed on the tensor are recorded \n",
        "tensor_32.shape, tensor_32.device, tensor_32.dtype"
      ],
      "metadata": {
        "id": "3jztkl96lsGz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "388c43b9-8908-4b2d-817c-d5e300b9eadb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), device(type='cpu'), torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aside from shape issues (tensor shapes don't match up), two of the other most common issues you'll come across in PyTorch are datatype and device issues.\n",
        "\n",
        "For example, one of tensors is torch.float32 and the other is torch.float16 (PyTorch often likes tensors to be the same format). Sometimes it throws an error especially when training large neural networks, other times it does not. However, it is better to be consistent with data types when performing calculations (mainly matrix multiplication) with tensors.\n",
        "\n",
        "Or one of your tensors is on the CPU and the other is on the GPU (PyTorch likes calculations between tensors to be on the same device). "
      ],
      "metadata": {
        "id": "Mo47gKIkuoT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating float16 tensor\n",
        "tensor_16 = torch.tensor(\n",
        "    [4.0, 9.0, 100.0, 12.],\n",
        "    dtype=torch.float16\n",
        ")\n",
        "tensor_16, tensor_16.dtype, tensor_16.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzDonpl6tIQM",
        "outputId": "3a692362-13c0-4b0c-888d-9ed7c7d3e388"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([  4.,   9., 100.,  12.], dtype=torch.float16),\n",
              " torch.float16,\n",
              " torch.Size([4]))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting information from tensors\n",
        "\n",
        "Three of the most common attributes about tensors are:\n",
        "\n",
        "*   shape - what shape is the tensor? (some operations require specific shape rules) \n",
        "*   dtype - what datatype are the elements within the tensor stored in? e.g., float32, int, long..etc.\n",
        "*   device - what device is the tensor stored on? (usually GPU or CPU, and less commonly TPU)\n",
        "\n"
      ],
      "metadata": {
        "id": "8lRFLiULwaZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "some_tensor = torch.rand(5, 10) # 5 rows 10 columns\n",
        "\n",
        "# Find out details about it\n",
        "print(some_tensor)\n",
        "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {some_tensor.device}\") # will default to CPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqul7_b3wGlR",
        "outputId": "995c2d8c-fdf4-4f8f-c42d-451fadd3a962"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5477, 0.3477, 0.7854, 0.7087, 0.8080, 0.7055, 0.5773, 0.7819, 0.8090,\n",
            "         0.1695],\n",
            "        [0.5310, 0.6643, 0.8081, 0.2583, 0.8319, 0.4102, 0.2413, 0.1573, 0.0412,\n",
            "         0.7788],\n",
            "        [0.4037, 0.9901, 0.1786, 0.6957, 0.7830, 0.4978, 0.5826, 0.3440, 0.0704,\n",
            "         0.4771],\n",
            "        [0.6919, 0.2559, 0.4427, 0.3884, 0.7486, 0.0687, 0.8772, 0.8260, 0.8402,\n",
            "         0.1360],\n",
            "        [0.3829, 0.1332, 0.7726, 0.0436, 0.4106, 0.0856, 0.5443, 0.0274, 0.6115,\n",
            "         0.8065]])\n",
            "Shape of tensor: torch.Size([5, 10])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Operations\n",
        "* Addition\n",
        "* Substraction\n",
        "* Multiplication (element-wise)\n",
        "* Division\n",
        "* Matrix multiplication\n",
        "\n",
        "##### Basic operations: \n",
        "* `+ `\n",
        "* `-`\n",
        "* `*`\n"
      ],
      "metadata": {
        "id": "0btWdukz1XxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of values and add a number to it\n",
        "tensor = torch.tensor([[1, 2, 3],\n",
        "                       [3, 77, 8]])\n",
        "tensor + 20 \n",
        "# will add 20 to all values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gjsk_USu1HQw",
        "outputId": "4ea882a7-60aa-42c0-bf20-8e8576b35048"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[21, 22, 23],\n",
              "        [23, 97, 28]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiply it by 10\n",
        "tensor * 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJC9hlG24hHv",
        "outputId": "ef1d28f7-f4c4-4ad8-c9e2-701c13e7053b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 10,  20,  30],\n",
              "        [ 30, 770,  80]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subtract\n",
        "tensor - 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge3NqiB94nB7",
        "outputId": "c31bd73f-f058-4378-e33e-b544f10f0e93"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-9, -8, -7],\n",
              "        [-7, 67, -2]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Can also use torch functions\n",
        "# But it is more common to use *\n",
        "torch.multiply(tensor, 10), torch.mul(tensor, 56)"
      ],
      "metadata": {
        "id": "4em3lXTO4xgI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebb5197a-ea52-4d6d-e585-88acae7a5183"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 10,  20,  30],\n",
              "         [ 30, 770,  80]]), tensor([[  56,  112,  168],\n",
              "         [ 168, 4312,  448]]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrix multiplication (Most Common Operation in Neural Networks)\n",
        "Using PyTorch's torch.matmul() method.\n",
        "The @ symbol is used for matrix multiplication as a short-hand.\n",
        "\n",
        "Two rules for matrix multiplication:\n",
        "1. Inner dimensions must match.\n",
        "* (4, 2) @ (3, 6) won't work\n",
        "* (5, 3) @ (3, 2) will work\n",
        "* (3, 2) @ (2, 3) will work\n",
        "\n",
        "2. Resulting matrix is of outer dimensions.\n",
        "* (2, 3) @ (3, 2) -> (2, 2)\n",
        "* (6, 2) @ (2, 8) -> (6, 8)\n"
      ],
      "metadata": {
        "id": "ujUuRepj8EAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Element-wise matrix multiplication\n",
        "tensor, tensor * tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EKUlmgB6_nJ",
        "outputId": "68751123-48d7-45c4-8be4-34fcc875a517"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 1,  2,  3],\n",
              "         [ 3, 77,  8]]), tensor([[   1,    4,    9],\n",
              "         [   9, 5929,   64]]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix multiplication\n",
        "tensor1 = torch.tensor([[10, 4, 7],\n",
        "                        [8, 9, 0],\n",
        "                        [5,8, 3]] # 3 x 3\n",
        ")\n",
        "tensor2 = torch.tensor([[10, 7],\n",
        "                        [8, 0],\n",
        "                        [5, 3]] # 3 x 2\n",
        ")\n",
        "torch.matmul(tensor1, tensor2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrrH5FQt9f0-",
        "outputId": "a555d653-0caa-42d1-8a90-4c4774c7d9af"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[167,  91],\n",
              "        [152,  56],\n",
              "        [129,  44]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Can also use the \"@\" symbol for matrix multiplication, though not much recommended for readability.\n",
        "tensor1 @ tensor2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBE-7X1A9qa0",
        "outputId": "48a71007-f650-4fc5-ae8d-94dd9e64b795"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[167,  91],\n",
              "        [152,  56],\n",
              "        [129,  44]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Matrix multiplication by hand \n",
        "# (avoid doing operations with for loops at all cost, they are computationally expensive)\n",
        "value = 0\n",
        "tensor = torch.tensor([3, 8, 9])\n",
        "for i in range(len(tensor1)):\n",
        "  value += tensor[i] * tensor[i]\n",
        "value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBQ8pfIZ-6bE",
        "outputId": "e833e733-51f9-439a-c0ad-0ec049265277"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 773 µs, sys: 957 µs, total: 1.73 ms\n",
            "Wall time: 2.01 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(154)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FSoPeCy_MsH",
        "outputId": "f1171d3d-5164-422d-d2cb-bf98e99e999f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 378 µs, sys: 0 ns, total: 378 µs\n",
            "Wall time: 441 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(154)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing matrix multiplication with loops takes lots of time (approximately 10x slower than PyTorch's matmul() function. \n",
        "That's because PyTorch uses vectorization and performs these operations in parallel.\n",
        "### Shape Errors\n",
        "This happens because the inner dimensions of multiplied metricies do not match. Can be solved with transpose (switch the dimensions of a given tensor). "
      ],
      "metadata": {
        "id": "bAcvA1lxAbCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shapes need to be in the right way  \n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11], \n",
        "                         [9, 12]], dtype=torch.float32)\n",
        "\n",
        "# torch.matmul(tensor_A, tensor_B) # (this will cause error)\n",
        "\n",
        "# View tensor_A and tensor_B\n",
        "print(tensor_A)\n",
        "print(tensor_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hou6T6Gv_sEs",
        "outputId": "e265c12f-4b5a-4466-8c34-78f4f562c8fd"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7., 10.],\n",
            "        [ 8., 11.],\n",
            "        [ 9., 12.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View tensor_A and tensor_B.T\n",
        "print(tensor_A)\n",
        "print(tensor_B.T)\n",
        "# Same as above\n",
        "# Now we can multiply both since inner dimensions match. (3, 2) and (2, 3)\n",
        "print(torch.transpose(tensor_B, 0, 1))\n",
        "print(f\"Multiplying...dim A: {tensor_A.shape}, dim_B: {tensor_B.T.shape}: \" )\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output) \n",
        "print(f\"\\nOutput shape: {output.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyontSmTB-7-",
        "outputId": "48b4dff2-30d3-420f-df01-0473a22fd240"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7.,  8.,  9.],\n",
            "        [10., 11., 12.]])\n",
            "tensor([[ 7.,  8.,  9.],\n",
            "        [10., 11., 12.]])\n",
            "Multiplying...dim A: torch.Size([3, 2]), dim_B: torch.Size([2, 3]): \n",
            "tensor([[ 27.,  30.,  33.],\n",
            "        [ 61.,  68.,  75.],\n",
            "        [ 95., 106., 117.]])\n",
            "\n",
            "Output shape: torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.mm is a shortcut for matmul\n",
        "torch.mm(tensor_A, tensor_B.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuEIWyxDCuPI",
        "outputId": "761e9daf-b331-464e-c927-ee27bac8313f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 27.,  30.,  33.],\n",
              "        [ 61.,  68.,  75.],\n",
              "        [ 95., 106., 117.]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** A matrix multiplication like this is also referred to as the **dot product** of two matrices.\n",
        "\n",
        "## Finding the min, max, mean, sum, etc (Aggregation)"
      ],
      "metadata": {
        "id": "Oi0tItKpEncI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(0, 100, 10)\n",
        "print(x)\n",
        "print(f\"Minimum: {x.min()}\")\n",
        "print(f\"Maximum: {x.max()}\")\n",
        "# print(f\"Mean: {x.mean()}\") # this will error\n",
        "print(f\"Mean: {x.type(torch.float32).mean()}\") # won't work without float datatype\n",
        "print(f\"Sum: {x.sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Snv9wEYNEeYQ",
        "outputId": "4918dfbe-8f32-4e9a-859f-31ce3dba5dbf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "Minimum: 0\n",
            "Maximum: 90\n",
            "Mean: 45.0\n",
            "Sum: 450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Other way:\n",
        "torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)\n",
        "# Note that .mean() works only with the default data type float. Cannot work with int."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy0m_j8kEmgZ",
        "outputId": "f0507aae-c843-4811-b05a-0df3ce9d2c61"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(90), tensor(0), tensor(45.), tensor(450))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns index of max and min values\n",
        "print(f\"Index where max value occurs: {x.argmax()}\")\n",
        "print(f\"Index where min value occurs: {x.argmin()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1M2MPnHZGgDe",
        "outputId": "de56620e-c1f7-4976-8b85-b4ce02db0140"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index where max value occurs: 9\n",
            "Index where min value occurs: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor datatype, reshaping, stacking, squeezing and unsqueezing"
      ],
      "metadata": {
        "id": "NHZcRJeuHVpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor and check its datatype\n",
        "tensor = torch.arange(10., 100., 10.)\n",
        "print(tensor.dtype) # default is float32\n",
        "\n",
        "tensor = torch.arange(10, 100, 10) # Removed the dots\n",
        "print(tensor.dtype)\n",
        "\n",
        "# Create a float16 tensor\n",
        "tensor_float16 = tensor.type(torch.float16)\n",
        "print(tensor_float16.dtype)\n",
        "\n",
        "# Create a int8 tensor\n",
        "tensor_int8 = tensor.type(torch.int8)\n",
        "print(tensor_int8.dtype)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ErQWfiBHHXK",
        "outputId": "5f68f91c-29d7-4de9-d66a-94e993dfe27a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "torch.int64\n",
            "torch.float16\n",
            "torch.int8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because deep learning models (neural networks) are all about manipulating tensors in some way. And because of the rules of matrix multiplication, if you've got shape mismatches, you'll run into errors. Squeeze, unsqueeze, and reshape help you make the right elements of your tensors are mixing with the right elements of other tensors."
      ],
      "metadata": {
        "id": "7YzH_XUDl_SD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(1., 8.)\n",
        "x, x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KStCEpBJHhAw",
        "outputId": "315183d2-6f9a-43fb-9878-89b90e9836b1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an extra dimension\n",
        "x_reshaped = x.reshape(7, 1) # multiplying dimensions should be equal to the old dimensions.\n",
        "x_reshaped, x_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KBUuT56mV1M",
        "outputId": "5eb8d414-365f-4992-8351-9771d258243e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.],\n",
              "         [2.],\n",
              "         [3.],\n",
              "         [4.],\n",
              "         [5.],\n",
              "         [6.],\n",
              "         [7.]]), torch.Size([7, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([\n",
        "    list(torch.arange(1, 10)),\n",
        "    list(torch.arange(1, 10))\n",
        "\n",
        "]) #---> 2*9 = 18\n",
        "print(list(x))\n",
        "x_reshaped = x.reshape(1, 18) #---> 1*18= 18\n",
        "x_reshaped, x_reshaped.shape\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpLxjaZImc3c",
        "outputId": "8acb873d-2d4c-4129-edc1-294f88f4a09c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9]]),\n",
              " torch.Size([1, 18]))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .view() creates a view of the tensor that shares the same memory address, means if we change the original tensor, the view will change as well.\n",
        "z = x.view(1, 18)\n",
        "z, z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8XyeTk0nCHz",
        "outputId": "4a2a1077-528f-4311-db25-719729486686"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9]]),\n",
              " torch.Size([1, 18]))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing z changes x\n",
        "z[0, 0] = 44\n",
        "print(z)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apYPpQIcojOD",
        "outputId": "ffa86acc-d5b2-4783-8fb6-e6646c400dbb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[44,  2,  3,  4,  5,  6,  7,  8,  9,  1,  2,  3,  4,  5,  6,  7,  8,  9]])\n",
            "tensor([[44,  2,  3,  4,  5,  6,  7,  8,  9],\n",
            "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To stack tensors on top of eachother, torch.stack(). \n",
        "\n"
      ],
      "metadata": {
        "id": "S0FcDYRFp_bU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack tensors on top of each other\n",
        "x_stacked = torch.stack([x, x, x, x], dim=0) # try changing dim to dim=1 and see what happens\n",
        "print(x_stacked)\n",
        "print(x_stacked.ndim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aqCtOVVpRwf",
        "outputId": "e0bf0ffd-2942-4908-aef1-a2895fb3c9e0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[44,  2,  3,  4,  5,  6,  7,  8,  9],\n",
            "         [ 1,  2,  3,  4,  5,  6,  7,  8,  9]],\n",
            "\n",
            "        [[44,  2,  3,  4,  5,  6,  7,  8,  9],\n",
            "         [ 1,  2,  3,  4,  5,  6,  7,  8,  9]],\n",
            "\n",
            "        [[44,  2,  3,  4,  5,  6,  7,  8,  9],\n",
            "         [ 1,  2,  3,  4,  5,  6,  7,  8,  9]],\n",
            "\n",
            "        [[44,  2,  3,  4,  5,  6,  7,  8,  9],\n",
            "         [ 1,  2,  3,  4,  5,  6,  7,  8,  9]]])\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# squeeze() removes all single dimensions from a tensor. \n",
        "tensor = torch.tensor([[[4,7,7,9]]])\n",
        "print(f\"Previous tensor: {tensor}\")\n",
        "print(f\"Previous shape: {tensor.shape}\")\n",
        "\n",
        "# Remove extra dimension from x_reshaped\n",
        "t_squeezed = tensor.squeeze()\n",
        "print(f\"\\nNew tensor: {t_squeezed}\")\n",
        "print(f\"New shape: {t_squeezed.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1jRxBMA_Y2g",
        "outputId": "a8118360-ce97-4230-cba7-74e386572a47"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor: tensor([[[4, 7, 7, 9]]])\n",
            "Previous shape: torch.Size([1, 1, 4])\n",
            "\n",
            "New tensor: tensor([4, 7, 7, 9])\n",
            "New shape: torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.unsqueeze() adds a dimension value of 1 at a specific index.\n",
        "print(f\"Previous tensor: {t_squeezed}\")\n",
        "print(f\"Previous shape: {t_squeezed.shape}\")\n",
        "\n",
        "\n",
        "## Add an extra dimension with unsqueeze to dim=1\n",
        "t_unsqueezed = t_squeezed.unsqueeze(dim=1)\n",
        "print(f\"\\nNew tensor with extra dimension at 1: {t_unsqueezed}\")\n",
        "print(f\"New shape: {t_unsqueezed.shape}\")\n",
        "\n",
        "## Add an extra dimension with unsqueeze to dim=0\n",
        "t_unsqueezed = t_squeezed.unsqueeze(dim=0)\n",
        "print(f\"\\nNew tensor with extra dimension at 0: {t_unsqueezed}\")\n",
        "print(f\"New shape: {t_unsqueezed.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gkVK4kHAW7f",
        "outputId": "d3532499-ad82-4d4e-b7b4-1946821e0981"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor: tensor([4, 7, 7, 9])\n",
            "Previous shape: torch.Size([4])\n",
            "\n",
            "New tensor with extra dimension at 1: tensor([[4],\n",
            "        [7],\n",
            "        [7],\n",
            "        [9]])\n",
            "New shape: torch.Size([4, 1])\n",
            "\n",
            "New tensor with extra dimension at 0: tensor([[4, 7, 7, 9]])\n",
            "New shape: torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensor with specific shape, then permuting (rearranging) its dimensions.\n",
        "x_original = torch.rand(size=(224, 224, 3))\n",
        "# Permute the original tensor to rearrange the axis order (0, 1, 2) ----> (2, 0, 1)\n",
        "x_permuted = x_original.permute(2, 0, 1) \n",
        "# 0->1,\n",
        "# 1->2,\n",
        "# 2->0 \n"
      ],
      "metadata": {
        "id": "z041WM6WBGpo"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's index bracket by bracket\n",
        "x = torch.arange(1, 10)\n",
        "x = torch.stack([x, x, x, x, x]).unsqueeze(dim=0)\n",
        "print(x)\n",
        "\n",
        "print(f\"First square bracket:\\n{x[0]}\") # getting a matrix\n",
        "print(f\"Second square bracket: {x[0][0]}\") # getting the 1st row of that matrix \n",
        "print(f\"Third square bracket: {x[0][0][0]}\") # element"
      ],
      "metadata": {
        "id": "hzdx09zoCitW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de468d7e-ab62-4eb7-8000-3ceb73e93d1f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
            "         [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
            "         [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
            "         [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
            "         [1, 2, 3, 4, 5, 6, 7, 8, 9]]])\n",
            "First square bracket:\n",
            "tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
            "        [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
            "        [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
            "        [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
            "        [1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
            "Second square bracket: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "Third square bracket: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also use : to specify \"all values in this dimension\" and then use a comma (,) to add another dimension.\n",
        "\n"
      ],
      "metadata": {
        "id": "BMurMJdH2luk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[\n",
        "      [1, 2, 3, 4],\n",
        "      [10, 20, 30, 40],\n",
        "      [100, 200, 300, 400],\n",
        "      [1000, 2000, 3000, 4000]]])\n",
        "print(x[:])\n",
        "print(x[:, 1, :])\n",
        "print(x[:, :, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYK-Bl5e1xWm",
        "outputId": "98380fd1-711f-4b0c-e0c7-0b65a2eca4ff"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[   1,    2,    3,    4],\n",
            "         [  10,   20,   30,   40],\n",
            "         [ 100,  200,  300,  400],\n",
            "         [1000, 2000, 3000, 4000]]])\n",
            "tensor([[10, 20, 30, 40]])\n",
            "tensor([[   1,   10,  100, 1000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch tensors & NumPy"
      ],
      "metadata": {
        "id": "_RgoTcA04RM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array = np.arange(1.0, 8.0)\n",
        "# Converting from numpy to tensor\n",
        "tensor = torch.from_numpy(array)\n",
        "print(array, tensor, tensor.dtype)\n",
        "tensor = tensor.type(torch.float32)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJflDG6-2qzA",
        "outputId": "795bfc5e-0e9c-4f6d-c357-e194c7476956"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 2. 3. 4. 5. 6. 7.] tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64) torch.float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note** By default, NumPy arrays are created with the datatype float64 and if you convert it to a PyTorch tensor, it'll keep the same datatype (as above).\n",
        "\n"
      ],
      "metadata": {
        "id": "WYabby495193"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor to NumPy array\n",
        "tensor = torch.ones(10) # create a tensor of ones with dtype=float32\n",
        "numpy_tensor = tensor.numpy() # will be dtype=float32 unless changed\n",
        "tensor, numpy_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIsq5yTO5iKM",
        "outputId": "81a2069a-5073-4ab9-ef2f-e50ca40178cf"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reproducibility (trying to take the randomness out of random) Random Seeds\n",
        "Neural networks start with random numbers to describe patterns in data (these numbers are bad descriptions) and try to improve those random numbers using tensor operations ml algorithms to better describe patterns in data.\n",
        "\n",
        "In short:\n",
        "`start with random numbers -> tensor operations -> try to make better (again and again and again)` \n",
        "\n",
        "**Reproducibility**: Getting the same random numbers again.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zz8F79LlA7em"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two random tensors\n",
        "random_tensor_A = torch.rand(3, 4)\n",
        "random_tensor_B = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
        "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
        "print(f\"Does Tensor A equal Tensor B? (anywhere)\")\n",
        "random_tensor_A == random_tensor_B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVY5kZC0AEQ5",
        "outputId": "ea5fe0b1-6b27-408e-b937-0e8b00807844"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor A:\n",
            "tensor([[0.9601, 0.0256, 0.4391, 0.7214],\n",
            "        [0.5082, 0.5991, 0.4742, 0.6298],\n",
            "        [0.3299, 0.0543, 0.2164, 0.7189]])\n",
            "\n",
            "Tensor B:\n",
            "tensor([[0.4061, 0.9625, 0.4351, 0.0213],\n",
            "        [0.5543, 0.7348, 0.5461, 0.0605],\n",
            "        [0.8355, 0.3648, 0.5487, 0.3939]])\n",
            "\n",
            "Does Tensor A equal Tensor B? (anywhere)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False, False, False],\n",
              "        [False, False, False, False],\n",
              "        [False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Set the random seed, usually it is any number but 42 is commonly used.\n",
        "RANDOM_SEED=45 # try changing this to different values and see what happens to the numbers below\n",
        "torch.manual_seed(seed=RANDOM_SEED) \n",
        "random_tensor_C = torch.rand(3, 4)\n",
        "\n",
        "# Have to reset the seed every time a new rand() is called \n",
        "# Without this, tensor_D would be different to tensor_C \n",
        "torch.random.manual_seed(seed=RANDOM_SEED) # try commenting this line out and seeing what happens\n",
        "random_tensor_D = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
        "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
        "print(f\"Does Tensor C equal Tensor D? (anywhere)\")\n",
        "random_tensor_C == random_tensor_D"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpAE2TxHDBMc",
        "outputId": "307705a2-bbf9-47dd-bc2a-b9d262cd5b52"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor C:\n",
            "tensor([[0.1869, 0.9613, 0.6834, 0.8988],\n",
            "        [0.0505, 0.5555, 0.7861, 0.0566],\n",
            "        [0.7842, 0.1480, 0.0388, 0.1037]])\n",
            "\n",
            "Tensor D:\n",
            "tensor([[0.1869, 0.9613, 0.6834, 0.8988],\n",
            "        [0.0505, 0.5555, 0.7861, 0.0566],\n",
            "        [0.7842, 0.1480, 0.0388, 0.1037]])\n",
            "\n",
            "Does Tensor C equal Tensor D? (anywhere)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running tensors on GPUs \n",
        "Deep learning algorithms require a lot of numerical operations (mainly matrix multiplications).\n",
        "\n",
        "And by default these operations are often done on a CPU.\n",
        "\n",
        "However, there's another common piece of hardware called a GPU (graphics processing unit), which is often much faster at performing the specific types of operations neural networks need than CPUs."
      ],
      "metadata": {
        "id": "q9qfukkNDvLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzEnWayiDt-C",
        "outputId": "ec29372e-67ad-43f6-f2d4-8c478e5d5b62"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jan 31 00:02:07 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P0    27W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ways to get a GPU:**\n",
        "1. Google Colab.\n",
        "2. Buying a GPU.\n",
        "3. Cloud AWS/ Azure/ GCP.\n",
        "\n",
        "### 2. Running PyTorch on GPU"
      ],
      "metadata": {
        "id": "ECkPiN2NDudC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seting up device agnostic code, it will use GPU if available. Writing device agnostic code is best practice.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "kHxn2-FADc6Y",
        "outputId": "4558f070-075b-453f-c034-2999e62a0ff6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count number of devices\n",
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG3F--l5DslK",
        "outputId": "170036a0-d66b-4de1-afed-21f7ebb4bc7c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Putting tensors (and models) on the GPU\n",
        "\n",
        "You can put tensors (and models, we'll see this later) on a specific device by calling `to(device) on them."
      ],
      "metadata": {
        "id": "acbBALAUH5dZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensor (default on CPU)\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "# Tensor not on GPU, on CPU by default\n",
        "print(tensor, tensor.device)\n",
        "\n",
        "# Move tensor to GPU (if available)\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu\n",
        "\n",
        "# Moving tensor back to CPU\n",
        "\n",
        "# The next line will result an error because numpy() arrays must live in a CPU. \n",
        "# tensor_on_gpu.numpy() \n",
        "\n",
        "\n",
        "# Instead, copy the tensor back to cpu, so we can convert them to numpy.\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrrRTup2Hr8R",
        "outputId": "2a7c0dc7-d92a-42fc-ca4b-d513dbcc8567"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zkayVPw9IXIJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}